{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = '5102696637:AAHcm9cOmIF7-GyG7nHHJYA_yZCGSWSTu60'\n",
    "tg_chat_id = '1126129331'\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):\n",
    "    requests.post(\n",
    "        'https://api.telegram.org/' +\n",
    "        'bot{}/sendMessage'.format(tg_api_token), \n",
    "        params=dict(chat_id=tg_chat_id, text=text)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distributions_of_labels(labels_np):\n",
    "    unique_values, counts = np.unique(labels_np, axis=0, return_counts=True)\n",
    "    print(f\"{unique_values} {counts}\")\n",
    "    print(f\"{unique_values} {counts/sum(counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"input_model_data\",'rb')\n",
    "data=pickle.load(f,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features = data[\"validation_data_features\"]\n",
    "validation_targets = data[\"validation_data_targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33066, 630, 5), (33066,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features.shape, validation_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [12502  8100  4677  2479  5308]\n",
      "[0 1 2 3 4] [0.3780923  0.24496462 0.14144438 0.07497127 0.16052743]\n"
     ]
    }
   ],
   "source": [
    "print_distributions_of_labels(validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_data(features, targets, label_id):\n",
    "    indexes = np.where(targets == label_id)\n",
    "    return np.delete(features, indexes, axis=0), np.delete(targets, indexes)\n",
    "\n",
    "def update_labels(targets, old_label_id, new_label_id):\n",
    "    '''baseline = 0, stress = 1, amusement = 2'''\n",
    "    indexes = np.where(targets == old_label_id)\n",
    "    targets[indexes] = new_label_id\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15256, 630, 5) (15256,)\n",
      "(15256, 630, 5) (15256,)\n",
      "[0 1 2] [8100 4677 2479]\n",
      "[0 1 2] [0.53093865 0.30656791 0.16249345]\n"
     ]
    }
   ],
   "source": [
    "for label_id in [0, 4, 5]:\n",
    "    validation_features, validation_targets = remove_data(validation_features, validation_targets, label_id)\n",
    "print(validation_features.shape, validation_targets.shape)\n",
    "\n",
    "for old_label_id, new_label_id in [(1, 0), (2, 1), (3, 2)]:\n",
    "    validation_targets = update_labels(validation_targets, old_label_id, new_label_id)\n",
    "print(validation_features.shape, validation_targets.shape)\n",
    "print_distributions_of_labels(validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chest_signal_available = ['ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
    "num_features = len(chest_signal_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = (90*700)//100\n",
    "step_slinding_window = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment = \"1,5min-1sec-60percent-100pts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.path.join(\"models\", current_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['softmax_lstm_baseline_rmsprop',\n",
       " 'softmax_gru_baseline_rmsprop',\n",
       " 'softmax_lstm_baseline_nadam',\n",
       " 'softmax_lstm_baseline_adam',\n",
       " 'softmax_gru_baseline_adam',\n",
       " 'softmax_gru_baseline_nadam']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_available = os.listdir(models_path)\n",
    "models_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 11:21:51.753262: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-31 11:21:52.075235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 561 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'softmax_lstm_baseline_rmsprop': <keras.engine.sequential.Sequential at 0x7f7ff4474dc0>,\n",
       " 'softmax_gru_baseline_rmsprop': <keras.engine.sequential.Sequential at 0x7f7c16b29580>,\n",
       " 'softmax_lstm_baseline_nadam': <keras.engine.sequential.Sequential at 0x7f7c16b29550>,\n",
       " 'softmax_lstm_baseline_adam': <keras.engine.sequential.Sequential at 0x7f7c003a1250>,\n",
       " 'softmax_gru_baseline_adam': <keras.engine.sequential.Sequential at 0x7f7b40472220>,\n",
       " 'softmax_gru_baseline_nadam': <keras.engine.sequential.Sequential at 0x7f7b3034cfa0>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_evaluate = {}\n",
    "\n",
    "for model_name in models_available:\n",
    "    models_to_evaluate[model_name] = load_model(os.path.join(models_path, model_name))\n",
    "    \n",
    "models_to_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, classification_report\n",
    "from tensorflow import convert_to_tensor\n",
    "\n",
    "labels = [ \"Baseline\", \"Stress\", \"Amusement\" ]\n",
    "\n",
    "pacient_state = {\n",
    "    0: \"Not Defined/Transient\",\n",
    "    1: \"Baseline\",\n",
    "    2: \"Stress\",\n",
    "    3: \"Amusement\",\n",
    "    4: \"Meditation\",\n",
    "    5: \"Error/Not Labeled\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 11:21:59.054598: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n",
      "2022-01-31 11:21:59.126404: E tensorflow/stream_executor/dnn.cc:764] CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(2066): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'\n",
      "2022-01-31 11:21:59.126462: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_rnn_ops.cc:1562 : INTERNAL: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 5, 128, 1, 630, 32, 128] \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "   Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 5, 128, 1, 630, 32, 128] \n\t [[{{node CudnnRNN}}]]\n\t [[sequential_3/lstm_3/PartitionedCall]] [Op:__inference_predict_function_38898]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3103490/4278448381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_to_evaluate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-stress-detection/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env-stress-detection/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:    Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 5, 128, 1, 630, 32, 128] \n\t [[{{node CudnnRNN}}]]\n\t [[sequential_3/lstm_3/PartitionedCall]] [Op:__inference_predict_function_38898]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "font = {'family' : 'normal',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 30}\n",
    "plt.rc(\"font\",**font)\n",
    "\n",
    "y_test = validation_targets\n",
    "\n",
    "for model_name in models_to_evaluate:\n",
    "    \n",
    "    model = models_to_evaluate[model_name]\n",
    "    \n",
    "    y_pred_prob = model.predict( x = convert_to_tensor(validation_features) )\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(len(y_pred_prob)):\n",
    "        predictions.append(np.argmax(y_pred_prob[i]))\n",
    "    \n",
    "    y_pred = np.array(predictions)\n",
    "\n",
    "    df_y = pd.DataFrame({\n",
    "        \"y_test\": y_test,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "\n",
    "    y_test_label = np.array([pacient_state[i] for i in y_test])\n",
    "    y_pred_label = np.array([pacient_state[i] for i in y_pred])\n",
    "\n",
    "    cm = confusion_matrix(df_y[\"y_test\"].to_list(), df_y[\"y_pred\"].to_list())\n",
    "    cm_df = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "    \n",
    "    print(f\"\\n\\n############### START MODEL {model_name} ###############\\n\\n\")\n",
    "\n",
    "    plt.figure(figsize=(30,15))\n",
    "    sns.heatmap(cm_df, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "    plt.title(f'{model_name} - Multi-Classification Confusion Matrix')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'Classification Report: \\n\\n{classification_report(df_y[\"y_test\"], df_y[\"y_pred\"], target_names=labels)}')\n",
    "    print(f'Matthews Correlation: {matthews_corrcoef(df_y[\"y_test\"], df_y[\"y_pred\"])}')\n",
    "    \n",
    "    print(f\"\\n\\n############### END MODEL {model_name} ###############\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c695cf195cac5fc0f6fda570195130509dbc2d1415249d5db323ab804dd63d69"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
